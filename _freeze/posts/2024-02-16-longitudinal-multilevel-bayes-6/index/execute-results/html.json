{
  "hash": "7646982c921836d83339da20e1b683e1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bayesian analysis of longitudinal multilevel data - part 6  \ndescription: Part 6 of a tutorial showing how to fit directly with Stan and cmdstanr.\nauthor: Andreas Handel\ndate: 2024-02-16\ndate-modified: last-modified\naliases: \n  - ../longitudinal-multilevel-bayesian-analysis-6/\ncategories: \n  - R\n  - Data Analysis\n  - Bayesian\n  - Stan\nimage: \"featured.png\"\nimage-alt: \"Traceplot for several model parameters.\"\nexecute:\n  echo: true\nengine: knitr\n---\n\n\n\n\n# Overview\n\nThis is an extension of [a `cmdstanr`/Stan model](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) to fit longitudinal data using Bayesian multilevel/hierarchical/mixed-effects models. It is a continuation of a prior series of posts. You should [start at the beginning](/posts/2022-02-22-longitudinal-multilevel-bayes-1/). \n\nHere is [the Stan code for this example](stancode-4par.stan) and this is [the R script that runs everything](cmdstanr-4par-script.R).\n\n\n# Introduction\n\nAs described [in the prior post](/posts/2024-02-15-longitudinal-multilevel-bayes-5/) I want to implement an ordinary differential equation (ODE) model with Stan. I am slowly building up to that. \n\nWhile I had planned to hop from the 2-parameter `cmdstanr` and Stan model straight to the ODE model, I ended up deciding on one more intermediate step. Namely, I know that the ODE model I want to use has 4 main parameters, as opposed to the 2 parameters used here. I figured I might first build a more complex, 4-parameter non-ODE model before I try to implement the ODE model.\n\n\n# New deterministic model \n\nThe obvious candidate for that 4-parameter model is the equation I [mentioned previously](/posts/2022-02-25-longitudinal-multilevel-bayes-4/#alternative-model-for-time-series-trajectory) and that we ended up using in [one of our  papers](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10310361/). This equation was introduced as a good model to fit virus load data for an acute infection in [this paper](https://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-11-S1-S10).\n\nI'm deviating from the original paper by giving the parameters different names ($\\alpha$, $\\beta$, $\\gamma$, $\\eta$ instead of $p$, $g$, $d$, $k$) to be consistent with what I've been doing so far. \n\nAlso, since the original model was developed and set up with the assumptions that all 4 main parameters are positive, I need to ensure that by using the [previously described approach](/posts/2022-02-22-longitudinal-multilevel-bayes-1/#numerical-trickeries) of exponentiating the parameters. \n\nThis leads to this equation for the virus load trajectory.\n\n$$\n\\begin{aligned}\n\\mu_{i,t} = \\log\\left( \\frac{2 \\exp(\\alpha_{i})}{e^{-\\exp(\\beta_{i})  (t_i - \\exp(\\gamma_{i}))} + e^{\\exp(\\eta_{i})  (t_i - \\exp(\\gamma_{i}))}}\\right).\\\\\n\\end{aligned}\n$$\n\nHere's a bit of R code to explore this equation and to determine values for parameter priors that produce curves that are broadly consistent [with our simulated data](/posts/2022-02-22-longitudinal-multilevel-bayes-1/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# brief plotting of model to get idea for priors\nt = seq(0.1,40,length=100) \n# all parameters are the log of their original values\nalph = 30; # approximately the peak of virus\nbet = 1.0; # approx. growth rate\ngamm = 2.5; # approx. peak time\net = 0.3; # approx. decay rate\nnum  = 2*exp(alph)\nd1 = exp( - exp(bet)*(t - exp(gamm)) )\nd2 =  exp( exp(et) * (t - exp(gamm)) )\nmu = log( num /(d1 + d2) ) \nplot(t,mu, type = \"l\") #looks somewhat like virus load in acute \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/explore-model-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n## Full model structure\n\nThe rest of the model follow the previous one, just with more parameters. They all get their own equations. Here are the main components of the the new  model. \n\n<!-- I made one further change. Instead of assuming that the main model parameters depend linearly on the log of the dose, I instead treat the dose as categorical, with 3 dose levels. While one might generally expect a monotone relation between dose and virus load, there's not necessarily a reason to assume that it's linear. That will be especially true for the ODE model, where the mapping of some predictor variable on model parameters can be highly nonlinear. I tried a linear version first here, and found it to be too constricting, so I switched. -->\n\n\n$$\n\\begin{aligned}\n\\textrm{Outcome} \\\\\nY_{i,t}   \\sim \\mathrm{Normal}\\left(\\mu_{i,t}, \\sigma\\right) \\\\\n\\\\\n\\textrm{main model describing the virus trajectory} \\\\\n\\mu_{i,t} = \\log\\left( \\frac{2 \\exp(\\alpha_{i})}{e^{-\\exp(\\beta_{i})  (t_i - \\exp(\\gamma_{i}))} + e^{\\exp(\\eta_{i})  (t_i - \\exp(\\gamma_{i}))}}\\right).\\\\\n\\\\\n\\textrm{Deterministic models for main parameters} \\\\\n\\alpha_{i}   =  a_{0,i} + a_1 \\left(\\log (D_i) - \\log (D_m)\\right)  \\\\\n\\beta_{i}   =  b_{0,i} + b_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\gamma_{i}   =  g_{0,i} + g_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\eta_{i}   =  e_{0,i} + e_1 \\left(\\log (D_i) - \\log (D_m)\\right) \\\\\n\\end{aligned}\n$$\n\n\n## Parameter distributions\n\nTo fully specify the model, we need to give all parameters distributions. \nHere are the distributions for the population-level parameters. These do not vary between individuals. I'm choosing values for the prior distributions assuming that dose will lead to an increase in peak, time to peak and growth rate, and a reduction in decay rate. I'm only indicating the values with an `X` below since I keep changing them in the code and then they are out of sync here. Check the R script to see the chosen values.\n\n\n$$\n\\begin{aligned}\n\\textrm{population-level priors} \\\\\n\\sigma  \\sim \\mathrm{Exponential}(X)  \\\\\na_1 \\sim \\mathrm{Normal}(X,X) \\\\\nb_1 \\sim \\mathrm{Normal}(X,X) \\\\\ng_1 \\sim \\mathrm{Normal}(X,X) \\\\\ne_1 \\sim \\mathrm{Normal}(X,X) \\\\\n\\end{aligned}\n$$\n\n\nIn addition, we allow some parameters to differ between individuals, and we'll implement hyper-parameters to allow these values to inform each other across individuals. This is again the adaptive pooling concept discussed previously.\n\nI'm setting values for the prior distributions such that the virus load curve looks somewhat reasonable, based on the quick exploration of the model above. Again, not showing exact values here to not create confusion between what I write here and potentially different values I end up using in the code (and forgetting to update here). See the code for the actual values.\n\n\n$$\n\\begin{aligned}\n\\textrm{individal-level priors} \\\\\na_{0,i} \\sim \\mathrm{Normal}(\\mu_a, \\sigma_a) \\\\\nb_{0,i}  \\sim \\mathrm{Normal}(\\mu_b, \\sigma_b) \\\\\ng_{0,i} \\sim \\mathrm{Normal}(\\mu_g, \\sigma_g) \\\\\ne_{0,i}  \\sim \\mathrm{Normal}(\\mu_e, \\sigma_e) \\\\\n\\\\\n\\textrm{hyper priors} \\\\\n\\mu_a  \\sim \\mathrm{Normal}(X, X) \\\\\n\\mu_b  \\sim \\mathrm{Normal}(X, X) \\\\\n\\mu_g  \\sim \\mathrm{Normal}(X, X) \\\\\n\\mu_e  \\sim \\mathrm{Normal}(X, X) \\\\\n\\sigma_a  \\sim \\mathrm{Exponential}(X)  \\\\\n\\sigma_b  \\sim \\mathrm{Exponential}(X)  \\\\\n\\sigma_g  \\sim \\mathrm{Exponential}(X)  \\\\\n\\sigma_e  \\sim \\mathrm{Exponential}(X)  \\\\\n\\end{aligned}\n$$\n\n\n\nAnd that's the full model. The basic structure is the same as before, but the model is bigger because I'm now modeling the virus trajectory (given by $\\mu_{i,t}$) with 4 main parameters.\n\n\n# Model implementation\n\nWe'll follow the same setup as [in the previous post](/posts/2024-02-15-longitudinal-multilevel-bayes-5/).\nLinks to the Stan and R code files are given at the top of this document.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('here') #for file loading\nlibrary('dplyr') # for data manipulation\nlibrary('ggplot2') # for plotting\nlibrary('fs') #for file path\nlibrary('cmdstanr') #for model fitting\nlibrary('bayesplot') #for plotting results\nlibrary('posterior') #for post-processing\nlibrary('loo') #for model diagnostics\n```\n:::\n\n\nSome setup bits\n\n\n::: {.cell}\n\n```{.r .cell-code}\n############################################\n# some general definitions and setup stuff\n############################################\n#setting random number seed for reproducibility\nrngseed = 12345\n\n# I'll be saving results so we can use them without always running the model\n# Note that the files are often too large for standard Git/GitHub - where this project lives\n# Git Large File Storage should be able to handle it\n# I'm using a simple hack so I don't have to set up Git LFS\n# I am saving these large file to a folder that is synced with Dropbox\n# adjust accordingly for your setup\n#filepath = fs::path(\"C:\",\"Data\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\")\nfilepath = fs::path(\"D:\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\")\nfilename = \"cmdstanr4par.Rds\"\nstanfile <- here('posts','2024-02-16-longitudinal-multilevel-bayes-6',\"stancode-4par.stan\")\n```\n:::\n\n\n\n# Data\n\nWe'll use the same data as before. I'm making one more change. Instead of hard-coding the values for the prior distributions into the Stan code, I'm passing them into the Stan code as part of the data. This makes exploring the Stan model more flexible, I don't need to re-edit the Stan code if I want to try different values for the priors. I could do this for all parameters, but out of laziness, and because I don't change them much, I'm hard-coding the sigma parameters inside the Stan file.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# adjust as necessary\nsimdatloc <- here::here('posts','2022-02-22-longitudinal-multilevel-bayes-1','simdat.Rds')\nsimdat <- readRDS(simdatloc)\nNind = length(unique(simdat$m3$id))\nNtot =  length(simdat$m3$id)\n# values for prior distributions\n# allows for exploring different values without having to edit Stan model code\npriorvals = list(mu_a_mu = 1, mu_a_sd = 1,\n                 mu_b_mu = 1, mu_b_sd = 1,\n                 mu_g_mu = 2.5, mu_g_sd = 1,\n                 mu_e_mu = 0.3, mu_e_sd = 1,\n                 a1_mu = 0.5, a1_sd = 1,\n                 b1_mu = 0.1, b1_sd = 1,\n                 g1_mu = 0.1, g1_sd = 1,\n                 e1_mu = -0.1, e1_sd = 1\n)\n\n# all data as one list, this is how Stan needs it\nfitdatbase=list(id=simdat[[3]]$id,\n            outcome = simdat[[3]]$outcome,\n            time = simdat[[3]]$time,\n            dose_adj = simdat[[3]]$dose_adj[1:Nind], #first Nind values\n            Ntot =  Ntot,\n            Nind = Nind\n            )\nfitdat = c(fitdatbase, priorvals)\n```\n:::\n\n\n\n# Stan code\n\nI again wrote the Stan code in a separate Stan file. Here is the code. The model is basically like the previous one, updated to reflect the model equations above. As mentioned above, instead of hard-coding values for prior distributions inside the Stan code, I'm passing some of them into the code as data. The advantage of passing them in is that I can more quickly play around with different values and see how results change. It also ensures that I use the same values in all parts of the model (e.g., `model` and `generated quantities` blocks).\n\n```{.stan include=\"stancode-4par.stan\"}\n```\n\n\n\nThis loads and compiles the Stan model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make Stan model. \nstanmod1 <- cmdstanr::cmdstan_model(stanfile, \n                                    pedantic=TRUE, \n                                    force_recompile=TRUE)\n```\n:::\n\n\n\n\n\n## Model fitting settings\n\nThese are the settings for the model fitting routine. Basically the same as before, only more initial conditions now because we have more parameters. And of course different values, since our model changed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#settings for fitting\nfs_m1 = list(warmup = 1500,\n             sampling = 2000, \n             max_td = 20, #tree depth\n             adapt_delta = 0.99999,\n             chains = 5,\n             cores  = 5,\n             seed = rngseed,\n             save_warmup = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# separate definition of initial values, added to fs_m1 structure \n# a different sample will be drawn for each chain\n# there's probably a better way to do that than a for loop\nset.seed(rngseed) #make inits reproducible\ninit_vals_1chain <- function() (list(mu_a = runif(1,1,1.5), \n                                     mu_b = runif(1,0.8,1.2),\n                                     mu_g = runif(1,2,3),\n                                     mu_e = runif(1,0.2,0.6),\n                                     sigma_a = runif(1,0,1),\n                                     sigma_b = runif(1,0,1),\n                                     sigma_g = runif(1,0,1),\n                                     sigma_e = runif(1,0,1),\n                                     a0 = runif(Nind,1,1.5),\n                                     b0 = runif(Nind,0.8,1.5),\n                                     g0 = runif(Nind,1.5,2.5),\n                                     e0 = runif(Nind,0,1),\n                                     a1 = runif(1,0.5,0.6),\n                                     b1 = runif(1,0.1,0.1),\n                                     g1 = runif(1,0.1,0.1),\n                                     e1 = runif(1,-0.1,-0.1),\n                                     sigma = runif(1,0,1))\n                                )\ninits = NULL\nfor (n in 1:fs_m1$chains)\n{\n  inits[[n]] = init_vals_1chain()\n}\nfs_m1$init = inits\n```\n:::\n\n\n\n# Model fitting \n\nThis runs the model. It's not actually run here to speed up generation of this Quarto file, but the code chunk is in the R script, so you can run it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1 <- stanmod1$sample(data = fitdat,\n                          chains = fs_m1$chains,\n                          init = fs_m1$init,\n                          seed = fs_m1$seed,\n                          parallel_chains = fs_m1$chains,\n                          iter_warmup = fs_m1$warmup,\n                          iter_sampling = fs_m1$sampling,\n                          save_warmup = fs_m1$save_warmup,\n                          max_treedepth = fs_m1$max_td,\n                          adapt_delta = fs_m1$adapt_delta,\n                          output_dir = filepath\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1$save_object(fs::path(filepath,filename))\n```\n:::\n\n\n\n\n# Model result loading\n\nTo save time, we don't run the model each time, instead we save the results and load them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading previously saved fit.\n# useful if we don't want to re-fit\n# every time we want to explore the results.\n# since the file is too large for GitHub\n# it is stored in a local cloud-synced folder\n# adjust accordingly for your setup\nres_m1 <- readRDS(fs::path(filepath,filename))\n```\n:::\n\n\n# Model diagnostics\n\nFirst, we look at diagnostics from the fitting routine to make sure nothing obviously wrong shows up.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m1$cmdstan_diagnose()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProcessing csv files: D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-202402271819-1-39fd59.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-202402271819-2-39fd59.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-202402271819-3-39fd59.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-202402271819-4-39fd59.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-202402271819-5-39fd59.csvWarning: non-fatal error reading adaptation data\n\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\n210 of 17500 (1.20%) transitions ended with a divergence.\nThese divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\nTry increasing adapt delta closer to 1.\nIf this doesn't remove all divergences, try to reparameterize the model.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nThe E-BFMI, 0.07, is below the nominal threshold of 0.30 which suggests that HMC may have trouble exploring the target distribution.\nIf possible, try to reparameterize the model.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete.\n```\n\n\n:::\n:::\n\n\nOk, so the sampler isn't quite happy. We should sample more and more stringently, but that would take very long. So for the purpose of this investigation, and given that I'm only exploring this model as a stepping stone to the ODE model I'm really interested in, I'll leave it the way it is. If this were an actual research project, I would obviously need to improve the model performance.\n\nAnother important check are to make a few diagnostic plots. We'll first need to get the samples, both with and without warmups, to be able to make various figures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#this uses the posterior package to get draws\nsamp_m1 <- res_m1$draws(inc_warmup = FALSE, format = \"draws_df\")\nallsamp_m1 <- res_m1$draws(inc_warmup = TRUE, format = \"draws_df\")\n```\n:::\n\n\nNow we can look at a few figures. Here I'm again showing a trace plot and a pairs plot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only main parameters, excluding parameters that we have for each individual, is too much\nplotpars = c(\"a1\",\"b1\",\"g1\",\"e1\",\"sigma\")\nbayesplot::color_scheme_set(\"viridis\")\nbp1 <- bayesplot::mcmc_trace(samp_m1, pars = plotpars)\nbp2 <- bayesplot::mcmc_pairs(samp_m1, pars = plotpars)\nplot(bp1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bp2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m1-2.png){width=672}\n:::\n:::\n\n\nThe plots look reasonable. Well-mixing chains and no noticeable correlations among parameters.\n\n\n# Model results\n\nLet's also look at the results, namely the posterior distributions of the parameters. We'll again do both a table and a figure. We can't really compare with the values we used to generate the model since we are using a different model to fit the data, so we shouldn't expect any parameters to be similar. Thus, I'm not focusing further on the values. Again, for a real research project, you would want to carefully evaluate the parameters (after addressing the problems with the algorithm not working well).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(head(res_m1$summary(),15))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 Ã— 10\n   variable       mean   median      sd     mad       q5      q95  rhat ess_bulk\n   <chr>         <dbl>    <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n 1 lp__     -323.      -3.26e+2 3.78e+1 3.86e+1 -3.78e+2 -2.56e+2  1.04     99.0\n 2 sigma       5.87     5.86e+0 2.67e-1 2.68e-1  5.45e+0  6.33e+0  1.00   5947. \n 3 sigma_a     0.0240   2.13e-2 1.58e-2 1.54e-2  3.97e-3  5.39e-2  1.03    232. \n 4 sigma_b     0.0160   1.27e-2 1.30e-2 1.19e-2  1.49e-3  4.21e-2  1.04    145. \n 5 sigma_g     0.0118   1.00e-2 8.34e-3 7.92e-3  1.69e-3  2.80e-2  1.01    200. \n 6 sigma_e     0.275    2.68e-1 5.55e-2 5.31e-2  1.99e-1  3.77e-1  1.00   3843. \n 7 a1          0.112    1.12e-1 1.15e-2 1.17e-2  9.33e-2  1.32e-1  1.00   5467. \n 8 b1          0.105    1.05e-1 2.21e-2 2.21e-2  6.94e-2  1.41e-1  1.00   1531. \n 9 g1         -0.00380 -3.27e-3 1.58e-2 1.58e-2 -2.98e-2  2.16e-2  1.00   1623. \n10 e1         -0.299   -2.98e-1 3.55e-2 3.45e-2 -3.58e-1 -2.42e-1  1.00   1856. \n11 mu_a        0.869    8.69e-1 2.23e-2 2.21e-2  8.33e-1  9.06e-1  1.01   1017. \n12 mu_b        3.86     3.86e+0 4.36e-2 4.37e-2  3.79e+0  3.93e+0  1.01    514. \n13 mu_g        0.480    4.79e-1 3.13e-2 3.05e-2  4.32e-1  5.34e-1  1.02    487. \n14 mu_e        0.241    2.43e-1 6.63e-2 6.40e-2  1.28e-1  3.49e-1  1.00   3324. \n15 a0[1]       0.878    8.76e-1 3.42e-2 3.04e-2  8.26e-1  9.36e-1  1.00   2078. \n# â„¹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\nbp3 <- bayesplot::mcmc_dens_overlay(samp_m1, pars = plotpars)\nplot(bp3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/results_m1-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n# Priors and Posteriors\n\nNext, we'll compare prior and posterior distributions. This can give an indication if the priors were selected well or are too broad or overly influential. To be able to show priors, we needed all that extra information in the _generated quantities_ block in the Stan code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation to get in shape for plotting\npostdf1 <- samp_m1 %>% \n  select(!ends_with('prior')) %>% \n  select(!starts_with(\".\")) %>% \n  select(-\"lp__\") %>% \n  select(!contains(\"[\")) \n# awkward way of getting some further parameters\n# namely values from first individual for a0,b0,g0,e0\npostdf2 <- samp_m1 %>%\n           select(contains(\"0[1]\")) %>%\n           rename_with(~ gsub(\"[1]\", \"\", .x, fixed = TRUE) )\npostdf <- cbind(postdf1, postdf2) \npriordf <-  samp_m1 %>% \n  select(ends_with('prior')) %>% \n  rename_with(~ gsub(\"_prior\", \"\", .x, fixed = TRUE) ) \npostlong <- tidyr::pivot_longer(data = postdf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"posterior\")\npriorlong <- tidyr::pivot_longer(data = priordf, cols = everything() , names_to = \"parname\", values_to = \"value\") %>% mutate(type = \"prior\")\nppdf <- dplyr::bind_rows(postlong,priorlong)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_p1 <- ppdf %>%\n  ggplot() +\n  geom_density(aes(x = value, color = type), linewidth = 1) +\n  facet_wrap(\"parname\", scales = \"free\") +\n  theme_minimal()\nplot(m1_p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/prior_post_m1-1.png){width=672}\n:::\n:::\n\n\nThe plots show that the priors don't overly influence the results, the data dominates the posteriors (they move and get more peaked, an indication that the data controls the posterior shape).\n\n\n# Observed versus predicted\n\n\nAnother useful plot is to look at observed versus predicted results. This is shown in the following plot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\nm1_p2 <- bayesplot::ppc_dens_overlay(fitdat$outcome, as.matrix(ypred_df))\nplot(m1_p2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/obs_pred_m1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# just to get a picture that can be shown together with the post\n#ggsave(\"featured.png\",m1_p2)\n```\n:::\n\n\n\nThe data (black line, $y$ variable) and the model (thin green line, $y_{rep}$) are a bit off. That indicates that the model didn't fully capture the patterns found in the data and might need modification.\n\n\n# Cross-validation tests\n\nHere's again some further exploration via cross-validation with the `loo` package. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# uses loo package \nloo_m1 <- res_m1$loo(cores = fs_m1$chains, save_psis = TRUE)\nprint(loo_m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nComputed from 10000 by 264 log-likelihood matrix\n\n         Estimate   SE\nelpd_loo   -862.2 11.2\np_loo        29.7  3.4\nlooic      1724.3 22.3\n------\nMonte Carlo SE of elpd_loo is NA.\n\nPareto k diagnostic values:\n                         Count Pct.    Min. n_eff\n(-Inf, 0.5]   (good)     249   94.3%   812       \n (0.5, 0.7]   (ok)        13    4.9%   303       \n   (0.7, 1]   (bad)        2    0.8%   161       \n   (1, Inf)   (very bad)   0    0.0%   <NA>      \nSee help('pareto-k-diagnostic') for details.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(loo_m1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part1-1.png){width=672}\n:::\n:::\n\n\nSome values aren't too great. This again suggests that we need to tweak the model or run it longer with more stringent settings.\n\nHere's some more LOO diagnostics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nypred_df <- samp_m1 %>% select(starts_with(\"ypred\"))\nm1_p3 <- bayesplot::ppc_loo_pit_overlay(\n  y = fitdat$outcome,\n  yrep = as.matrix(ypred_df),\n  lw = weights(loo_m1$psis_object)\n)\nplot(m1_p3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/loo_m1_part2-1.png){width=672}\n:::\n:::\n\n\nThe marginal posterior predictive plot suggests some improvement might be possible (so that the solid line is more on top of the green lines). [See here for more](https://mc-stan.org/loo/articles/loo2-example.html).\n\n\n\n# Model predictions\n\nFinally, we again want to look at the actual data and the model predictions. It's exactly the same code as for the 2-parameter model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# averages and CI for \n# estimates of deterministic model trajectory\n# for each observation\n# this is computed in the transformed parameters block of the Stan code\nmu <- samp_m1 |>\n  select(starts_with(\"virus_pred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(mu) <- NULL\n\n# estimate and CI for prediction intervals\n# the predictions factor in additional uncertainty around the mean (mu)\n# as indicated by sigma\n# this is computed in the predicted-quantities block of the Stan code\n# the average of mu and preds should be more or less the same\n# but preds will have wider uncertainty due to the residual variation sigma\npreds <- samp_m1 |>\n  select(starts_with(\"ypred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(preds) <- NULL\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# change dose so it looks nicer in plot\ndose = as.factor(fitdat$dose_adj)\nlevels(dose)[1] <- \"low\"\nlevels(dose)[2] <- \"medium\"\nlevels(dose)[3] <- \"high\"\n\n#place everything into a data frame\nfitpred = data.frame(id = as.factor(fitdat$id),\n                     dose = dose,\n                     time = fitdat$time,\n                     Outcome = fitdat$outcome,\n                     Estimate = mu[,2],\n                     Qmulo = mu[,1], Qmuhi = mu[,3],\n                     Qsimlo = preds[,1], Qsimhi = preds[,3]\n)\n\n#make the plot\n#not including the prediction intervals since it looks too messy\npredplot <- ggplot(data = fitpred, aes(x = time, y = Estimate, group = id, color = dose ) ) +\n  geom_line() +\n  geom_ribbon(aes(x=time, ymin=Qmulo, ymax=Qmuhi, fill = dose, color = NULL), alpha=0.3, show.legend = F) +\n  #geom_ribbon(aes(x=time, ymin=Qsimlo, ymax=Qsimhi, fill = dose, color = NULL), alpha=0.1, show.legend = F) +\n  geom_point(aes(x = time, y = Outcome, group = id, color = dose), shape = 1, size = 2, stroke = 2) +\n  scale_y_continuous(limits = c(-30,50)) +\n  labs(y = \"Virus load\",\n       x = \"days post infection\") +\n  theme_minimal() \nplot(predplot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_predictions-1.png){width=672}\n:::\n:::\n\n\nThe model fits don't look that great. I'm not sure why the model isn't capturing the data better, if it needs more iterations and/or better choice of priors, or if there's something inherent about the structure of this model not being able to capture the data generated by the 2-parameter model, even though it is more flexible with its 4 parameters. I suspect it's the last one, it seems even though this new model has more parameters, and thus should be more flexible, it can't quite capture the more gentle increase and decrease of the data generated by the simpler model.\n\nIn a reasearch/real-world setting, I would try to explore the model, priors, algorithm to make sure 1) I don't have any remaining mistakes in my codeï¸ ðŸ™„, 2) The problem is not due to poor choice of priors or starting values, 3) the hierarchical structure is not constraining the model too much. If those are ruled out, change the model to something that is better able to capture the patterns seen in the data. \n\nIn fact, I did a bit of that and figured I'll show it too.\n\n\n\n# Alternative model\n\nSince the previous model isn't fitting too well, I wanted to understand a bit more why that might be. I decided to implement a simpler model. It's the same 4-parameter equation for the virus load as above, but with a simpler parameter structure. I only used individual-level parameters which are independent of each other, and there's no dependence on dose. The complete independence of each parameter from each other is expected to make the model too flexible and overfit. The dose dependence is the scientific question, so removing them makes the model scientifically pointless. But I wanted to see if a model that basically allows each individual to have their completely independent set of main model parameters could get me something that matches the data closer. In some sense, this is the most flexible model I can make. If that doesn't work, it suggests the underlying model for the virus load is not able to capture the pattern seen here.\n\nThis is the updated model. I would of course not need both the $\\alpha, \\beta, ...$ and $a_0, b_0,...$ parameters since they are the same here and just duplicates. I decided to keep it anyway so it's easier to compare to the above model - and I had to make fewer changes to the code ðŸ˜.\n\n$$\n\\begin{aligned}\n\\textrm{Outcome} \\\\\nY_{i,t}   \\sim \\mathrm{Normal}\\left(\\mu_{i,t}, \\sigma\\right) \\\\\n\\\\\n\\textrm{main model describing the virus trajectory} \\\\\n\\mu_{i,t} = \\log\\left( \\frac{2 \\exp(\\alpha_{i})}{e^{-\\exp(\\beta_{i})  (t_i - \\exp(\\gamma_{i}))} + e^{\\exp(\\eta_{i})  (t_i - \\exp(\\gamma_{i}))}}\\right).\\\\\n\\\\\n\\textrm{Deterministic models for main parameters} \\\\\n\\alpha_{i}   =  a_{0,i}   \\\\\n\\beta_{i}   =  b_{0,i}  \\\\\n\\gamma_{i}   =  g_{0,i}  \\\\\n\\eta_{i}   =  e_{0,i}  \\\\\n\\\\\n\\textrm{Priors} \\\\\na_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\nb_{0,i}  \\sim \\mathrm{Normal}(X, X) \\\\\ng_{0,i} \\sim \\mathrm{Normal}(X, X) \\\\\ne_{0,i}  \\sim \\mathrm{Normal}(X, X) \\\\\n\\sigma  \\sim \\mathrm{HalfCauchy}(X)  \\\\\n\\end{aligned}\n$$\n\n\n# Alternative model implementation\n\nHere's the code to set up and run this model.\nWe of course have a new Stan model and need to pick new priors and new initial conditions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n############################\n# Try an alternative model\n############################\nfilepath = fs::path(\"D:\",\"Dropbox\",\"datafiles\",\"longitudinalbayes\")\nfilename_simple = \"cmdstanr4par-simple.Rds\"\nstanfile <- here('posts','2024-02-16-longitudinal-multilevel-bayes-6',\"stancode-4par-simple.stan\")\nrngseed = 12345\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# need to update priors\npriorvals2 = list(a0_mu = 1, a0_sd = 1,\n                 b0_mu = 1, b0_sd = 1,\n                 g0_mu = 2.5, g0_sd = 1,\n                 e0_mu = 0.3, e0_sd = 1\n                )\nfitdat2 = c(fitdatbase,priorvals2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# need different initial values\nset.seed(rngseed) #make inits reproducible\ninit_vals_1chain <- function() (list(a0_mu = runif(Nind,1,1), \n                                    b0_mu = runif(Nind,0.8,1.2),\n                                     g0_mu = runif(Nind,2,3),\n                                     e0_mu = runif(Nind,0,0.5),\n                                   \n                                     a0_sd = runif(Nind,1,1),\n                                     b0_sd = runif(Nind,1,1),\n                                     g0_sd = runif(Nind,1,1),\n                                     e0_sd = runif(Nind,1,1),\n                                     sigma = runif(1,0,1))\n                                )\ninits = NULL\nfor (n in 1:fs_m1$chains)\n{\n  inits[[n]] = init_vals_1chain()\n}\nfs_m1$init = inits\n```\n:::\n\n\n\n# Stan Code\n\nThis is the updated Stan code. Here is the [file](stancode-4par-simple.stan).\n\n```{.stan include=\"stancode-4par-simple.stan\"}\n```\n\nCompiling the Stan model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# make Stan model. \nstanmod2 <- cmdstanr::cmdstan_model(stanfile, \n                                    pedantic=TRUE, \n                                    force_recompile=TRUE)\n```\n:::\n\n\n\n# Model run\n\nThis runs the model and saves results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# most of it the same as previously\nres_m2 <- stanmod2$sample(data = fitdat2,\n                          chains = fs_m1$chains,\n                          init = fs_m1$init,\n                          seed = rngseed,\n                          parallel_chains = fs_m1$chains,\n                          iter_warmup = fs_m1$warmup,\n                          iter_sampling = fs_m1$sampling,\n                          save_warmup = fs_m1$save_warmup,\n                          max_treedepth = fs_m1$max_td,\n                          adapt_delta = fs_m1$adapt_delta,\n                          output_dir = filepath\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m2$save_object(fs::path(filepath,filename_simple))\n```\n:::\n\n\n\n# Result exploration\n\nLoad results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m2 <- readRDS(fs::path(filepath,filename_simple))\n```\n:::\n\n\nGet the samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#this uses the posterior package to get draws\nsamp_m2 <- res_m2$draws(inc_warmup = FALSE, format = \"draws_df\")\nallsamp_m2 <- res_m2$draws(inc_warmup = TRUE, format = \"draws_df\")\n```\n:::\n\n\n\nDiagnostics. Still not quite right.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_m2$cmdstan_diagnose()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProcessing csv files: D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-simple-202402271836-1-5ba055.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-simple-202402271836-2-5ba055.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-simple-202402271836-3-5ba055.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-simple-202402271836-4-5ba055.csvWarning: non-fatal error reading adaptation data\n, D:/Dropbox/datafiles/longitudinalbayes/stancode-4par-simple-202402271836-5-5ba055.csvWarning: non-fatal error reading adaptation data\n\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n```\n\n\n:::\n:::\n\n\nA few plots. They look fairly reasonable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# only a few parameters\nplotpars = c(\"a0[1]\",\"b0[1]\",\"g0[1]\",\"e0[1]\",\"sigma\")\nbayesplot::color_scheme_set(\"viridis\")\nbp1 <- bayesplot::mcmc_trace(samp_m2, pars = plotpars)\nbp3 <- bayesplot::mcmc_dens_overlay(samp_m2, pars = plotpars)\nplot(bp1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bp3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_par_m2-2.png){width=672}\n:::\n:::\n\n\nComparing priors and posteriors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data manipulation to get in shape for plotting\n# start with manipulation of posterior parameters\npostdf1 <- samp_m2 %>% \n  select(!ends_with('prior')) %>% \n  select(contains(\"sigma\")) \n# akward way of getting some further parameters\n# namely values from first individual for a0,b0,g0,e0\npostdf2 <- samp_m2 %>%\n  select(contains(\"0[1]\")) %>%\n  rename_with(~ gsub(\"[1]\", \"\", .x, fixed = TRUE) )\npostdf <- cbind(postdf1, postdf2) \npostlong <- tidyr::pivot_longer(data = postdf, \n                                cols = everything() , \n                                names_to = \"parname\", \n                                values_to = \"value\") %>% \n  dplyr::mutate(type = \"posterior\")\n# manipulation of prior parameters\npriordf <-  samp_m2 %>% \n  select(ends_with('prior')) %>% \n  rename_with(~ gsub(\"_prior\", \"\", .x, fixed = TRUE) ) \npriorlong <- tidyr::pivot_longer(data = priordf, \n                                 cols = everything() , \n                                 names_to = \"parname\", \n                                 values_to = \"value\") %>% \n                        dplyr::mutate(type = \"prior\")\n\nppdf <- dplyr::bind_rows(postlong,priorlong)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2_p1 <- ppdf %>%\n  ggplot() +\n  geom_density(aes(x = value, color = type), linewidth = 1) +\n  facet_wrap(\"parname\", scales = \"free\") +\n  theme_minimal()\nplot(m2_p1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/prior_post_m2-1.png){width=672}\n:::\n:::\n\n\nSkipping over all the other diagnostics plot we did above.\n\n\n# Outcome predictions\n\nGoing straight to plotting of data and model predictions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu2 <- samp_m2 |>\n  select(starts_with(\"virus_pred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(mu) <- NULL\npreds2 <- samp_m2 |>\n  select(starts_with(\"ypred\")) |>\n  apply(2, quantile, c(0.05, 0.5, 0.95)) |>\n  t() \nrownames(preds) <- NULL\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# change dose so it looks nicer in plot\ndose = as.factor(fitdat2$dose_adj)\nlevels(dose)[1] <- \"low\"\nlevels(dose)[2] <- \"medium\"\nlevels(dose)[3] <- \"high\"\nfitpred2 = data.frame(id = as.factor(fitdat2$id),\n                     dose = dose,\n                     time = fitdat2$time,\n                     Outcome = fitdat2$outcome,\n                     Estimate = mu2[,2],\n                     Qmulo = mu2[,1], Qmuhi = mu2[,3],\n                     Qsimlo = preds2[,1], Qsimhi = preds2[,3]\n)\n\n#make the plot\n#not including the CI or prediction intervals since it looks too messy\npredplot2 <- ggplot(data = fitpred2, aes(x = time, y = Estimate, group = id, color = dose ) ) +\n  geom_line() +\n  #geom_ribbon(aes(x=time, ymin=Qmulo, ymax=Qmuhi, fill = dose, color = NULL), alpha=0.3, show.legend = F) +\n  #geom_ribbon(aes(x=time, ymin=Qsimlo, ymax=Qsimhi, fill = dose, color = NULL), alpha=0.1, show.legend = F) +\n  geom_point(aes(x = time, y = Outcome, group = id, color = dose), shape = 1, size = 2, stroke = 2) +\n  scale_y_continuous(limits = c(-30,50)) +\n  labs(y = \"Virus load\",\n       x = \"days post infection\") +\n  theme_minimal() \nplot(predplot2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_predictions_m2-1.png){width=672}\n:::\n:::\n\n\n\nThis doesn't really look any better compared to the other model. So I -- preliminarily -- conclude that the main 4-parameter deterministic model I use here to describe the virus load trajectories just can't capture the shape of the data generated by the simpler 2-parameter model.\n\n\n\n# Summary and continuation\n\nThis completes the 4-parameter model. I would not use this model if I really wanted to fit the data here. But I just wanted to get a working model, I'm not really interested in the model results. I just wanted to set the stage for the next version, which is the 4-parameter ODE model. So it's finally time to [tackle that one](/posts/2024-02-17-longitudinal-multilevel-bayes-7/).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}